==============================
Example: Second Level Pipeline
==============================

Write pipeline script
=====================

Now that we have defined how the structure of our pipeline and the connections
should be we can start with writing the pipeline script.


Import modules
~~~~~~~~~~~~~~

First we have to import all necessary modules.

.. code-block:: py

   ##################################
   """Setup level 2 vol pipeline""" #
   ##################################
   
   # collect all the con images for each contrast.
   contrast_ids = range(1,len(contrasts)+1)
   l2source = pe.Node(nio.DataGrabber(infields=['con']), name="l2source")
   l2source.inputs.template= experiment_dir + '/asens_normbrains_diff/asens_*/normcons/con_%04d_ants.nii'
   l2source.iterables = [('con',contrast_ids)] # iterate over all contrast images
   
   #Node: OneSampleTTest - to perform a simple statistical analysis of the contrasts from the group of subjects
   onesamplettestdes = pe.Node(interface=spm.OneSampleTTestDesign(), name="onesampttestdes")
   
   #Node: MultipleRegressionDesign - to perform a simple statistical analysis of the contrasts from the group of subjects
   #multipleRegDes = pe.Node(interface=spm.MultipleRegressionDesign(), name="multipleRegDes")
   #multipleRegDes.inputs.covariates = [dict(vector=[-0.301,0.521,1.759,0.097,1.388,0.445,0.304,2.421,1.595,-0.276,0.361,0.301,1.506,0.985,-1.039],
   #                                         name='metric_dprime_diff'),
   #                                    dict(vector=[1.555,1.806,0.767,1.5,1.878,0.582,0.99,0.574,2.12,3.423,0.909,0.783,-0.33,2.549,1.857],
   #                                         name='diff_dprime_diff')] 
   
   #Node: EstimateModel
   l2estimate = pe.Node(interface=spm.EstimateModel(), name="level2estimate")
   l2estimate.inputs.estimation_method = {'Classical' : 1}
   
   #Node: EstimateContrast
   l2conestimate = pe.Node(interface = spm.EstimateContrast(), name="level2conestimate")
   cont1 = ('Group','T', ['mean'],[1])
   l2conestimate.inputs.contrasts = [cont1]
   l2conestimate.inputs.group_contrast = True
   
   #Node: Threshold
   level2thresh = pe.Node(interface = spm.Threshold(), name="level2thresh")
   level2thresh.inputs.contrast_index = 1      #mandatory - contrast_index : (an integer) which contrast in the SPM.mat to use
   level2thresh.inputs.extent_fdr_p_threshold = 0.05
   level2thresh.inputs.height_threshold = 3
   level2thresh.inputs.extent_threshold = 1
   level2thresh.inputs.use_fwe_correction = False
   level2thresh.inputs.use_topo_fdr = True
   
   #Create 2-level pipeline and connect up all components
   level2 = pe.Workflow(name="level2")
   level2.base_dir = experiment_dir + nameOflevel2Out
   level2.connect([(l2source,onesamplettestdes,[('outfiles','in_files')]),
                   (onesamplettestdes,l2estimate,[('spm_mat_file','spm_mat_file')]),
                   (l2estimate,l2conestimate,[('spm_mat_file','spm_mat_file'),
                                              ('beta_images','beta_images'),
                                              ('residual_image','residual_image')]),
                   (l2conestimate, level2thresh,[('spm_mat_file','spm_mat_file'),
                                                 ('spmT_images','stat_image'),
                                                 ]),
   
                   ])
   
   
   ###################################
   """Setup level 2 surf pipeline""" #
   ###################################
   
   l2flow = pe.Workflow(name='l2_surf')
   l2flow.base_dir = experiment_dir + nameOflevel2Out + '_surf'

   #Setup a dummy node to iterate over contrasts and hemispheres
   l2inputnode = pe.Node(interface=util.IdentityInterface(fields=['contrasts','hemi']),
                         name='inputnode')
   l2inputnode.iterables = [('contrasts', range(1,len(contrasts)+1)),
                            ('hemi', ['lh','rh'])]
                                       
   #Use a datagrabber node to collect contrast images and registration files
   l2source_surf = pe.Node(interface=nio.DataGrabber(infields=['con_id'],
                                                     outfields=['con','reg']),
                           name='l2source_surf')
   l2source_surf.inputs.base_directory = experiment_dir + '/' + nameOflevel1Out + '/'
   l2source_surf.inputs.template = '*'
   l2source_surf.inputs.field_template = dict(con='surf_contrasts/_subject_id_*/con_%04d.img',
                                              reg='bbregister/_subject_id_*/*.dat')
   l2source_surf.inputs.template_args = dict(con=[['con_id']],reg=[[]])

   #Merge contrast images and registration files
   mergenode = pe.Node(interface=util.Merge(2, axis='hstack'),name='merge')

   def ordersubjects(files, subj_list):
       outlist = []
       for s in subj_list:
           for f in files:
               if '/_subject_id_%s/'%s in f:
                   outlist.append(f)
                   continue
       print outlist
   return outlist

   #Concatenate contrast images projected to fsaverage
   l2concat = pe.Node(interface=fs.MRISPreproc(), name='concat')
   l2concat.inputs.target = 'fsaverage'
   l2concat.inputs.fwhm = 5

   def list2tuple(listoflist):
       return [tuple(x) for x in listoflist]

   #Node: OneSampleTTest - Perform a one sample t-test
   l2ttest = pe.Node(interface=fs.OneSampleTTest(), name='onesample')

   #Node: Datasink - Create a datasink node to store important outputs
   datasink_2l = pe.Node(interface=nio.DataSink(), name="datasink_2l")
   datasink_2l.inputs.base_directory = experiment_dir
   datasink_2l.inputs.container = nameOflevel2Out[1:] + '_surf'

   #Create 2-level surf pipeline and connect up all components
   l2flow.connect([(l2inputnode,l2source_surf,[('contrasts','con_id')]),
                   (l2inputnode,l2concat,[('hemi','hemi')]),
	               (l2source_surf,mergenode,[(('con', ordersubjects, subjects),'in1'),
	                                         (('reg', ordersubjects, subjects),'in2')]),
                   (mergenode,l2concat,[(('out', list2tuple),'vol_measure_file')]),
                   (l2concat,l2ttest,[('out_file','in_file')]),
	               (l2ttest,datasink_2l,[('sig_file','sig_file')]),
	               ])


   ###############################################
   """Run the pipeline and generate the graph""" #
   ###############################################

   level2.write_graph(graph2use='flat')
   level2.run(plugin='MultiProc', plugin_args={'n_procs' : 2})

   #l2flow.write_graph(graph2use='flat')
   #l2flow.run(plugin='MultiProc', plugin_args={'n_procs' : 2})
