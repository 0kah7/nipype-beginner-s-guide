==============================
Example: Second Level Pipeline
==============================

In this example you will learn how to do a **second level analysis** on the volume and the surface. We want combine both pipelines in a common parent workflow. Of course this would be possible, but it is also a advantage to be able to run the pipelines seperately.

.. note::

   Before we can run the **second level analysis** on the volume we have to normalize the estimated volume contrasts from the first level pipeline into a common subject space. One method how you can achieve this will be covered in the chapter about ANTS.
   This normalization isn't required for a **second level analysis** on the surface. Because the second level surface analysis will be done with FreeSurfer, we can use the subject specific informations won from the recon-all process.


Preparation
===========

It doesn't matter if you are running you're analysis only on the volume, on the surface or both. As always we're beginning by importing the necessary modules and implementation of the experiment specific parameters.


Import modules
~~~~~~~~~~~~~~

.. code-block:: py

   import nipype.interfaces.freesurfer as fs # freesurfer
   import nipype.interfaces.io as nio        # i/o routines
   import nipype.interfaces.spm as spm       # spm
   import nipype.interfaces.utility as util  # utility
   import nipype.pipeline.engine as pe       # pypeline engine


Define experiment specific parameters
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: py

   #to better access the parent folder of the experiment
   experiment_dir = '~SOMEPATH/experiment'

   #list of subjectnames
   subjects = ['subject1', 'subject2', 'subject3']
   
   #second level analysis pipeline specific components
   level2Dir = 'results/level2'
   numberOfContrasts = 5 #number of contrasts you specified in the first level analysis
   contrast_ids = range(1,numberOfContrasts+1) #to create a list with value [1,2,3,4,5]

.. note::

   If you want to only analyse the 3rd and 4th contrasts, you could specify ``contrast_ids`` as ``range(3,5)`` which would create the list ``[3,4]``


Analysis on the Volume
======================

Grab the data
~~~~~~~~~~~~~

As always we first have to specify where the datagrabber node can find the data. Le's assume that we have stored our normalized estimated volume contrasts at '~SOMEPATH/experiment/result/level1_output/subject_name/normcons/'. This means the third contrast of the second subject would be at: '~SOMEPATH/experiment/result/level1_output/subject2/normcons/con_0001.nii'

.. code-block:: py

   #Node: DataGrabber - to collect all the con images for each contrast
   l2volSource = pe.Node(nio.DataGrabber(infields=['con']), name="l2volSource")
   l2volSource.inputs.template = experiment_dir + '/result/level1_output/subject*/normcons/con_%04d.nii'
   l2volSource.iterables = [('con',contrast_ids)] # iterate over all contrast images
   

You might be confused with the asterisk in ``l2volSource.inputs.template`` and that we didn't iterated over the subjects. This is because of the nature of a second level analysis. We take all estimated contrasts of each subject at once into the analysis, therefore the asterisk. We only have to iterate the conditions e.g. the number of the contrasts. 


Define nodes
~~~~~~~~~~~~

.. code-block:: py

   #Node: OneSampleTTest - to perform an one sample t-test analysis
   oneSampleTTestDes = pe.Node(interface=spm.OneSampleTTestDesign(), name="oneSampleTTestDes")

   #Node: EstimateModel - to estimate the model
   l2estimate = pe.Node(interface=spm.EstimateModel(), name="l2estimate")
   l2estimate.inputs.estimation_method = {'Classical' : 1}
   
   #Node: EstimateContrast - to estimate the contrast (in this example just one)
   l2conestimate = pe.Node(interface = spm.EstimateContrast(), name="l2conestimate")
   cont1 = ('Group','T', ['mean'],[1])
   l2conestimate.inputs.contrasts = [cont1]
   l2conestimate.inputs.group_contrast = True
   
   #Node: Threshold - to threshold the estimated contrast
   level2thresh = pe.Node(interface = spm.Threshold(), name="level2thresh")
   level2thresh.inputs.contrast_index = 1
   level2thresh.inputs.use_fwe_correction = False
   level2thresh.inputs.use_topo_fdr = True
   level2thresh.inputs.extent_threshold = 1
   #voxel threshold
   level2thresh.inputs.extent_fdr_p_threshold = 0.05
   #cluster threshold (value is in -ln()): 1.301 = 0.05; 2 = 0.01; 3 = 0.001,
   level2thresh.inputs.height_threshold = 3


.. note::

   Of course you can all different kinds of statistical analysis. Another example beside a one sample t-test would be multiple regression analysis. Such a node would look this:

   .. code-block:: py

      #Node: MultipleRegressionDesign - to perform a multiple regression analysis
      multipleRegDes = pe.Node(interface=spm.MultipleRegressionDesign(), name="multipleRegDes")
      multipleRegDes.inputs.covariates = [dict(vector=[-0.30,0.52,1.75], #regressor1 for 3 subjects
                                               name='nameOfRegressor1'),
                                          dict(vector=[1.55,-1.80,0.77], #regressor2 for 3 subjects
                                               name='nameOfRegressor2')] 



Establish a second level volume pipeline
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   
.. code-block:: py

   #Create 2-level vol pipeline and connect up all components
   l2volflow = pe.Workflow(name="l2volflow")
   l2volflow.base_dir = experiment_dir + level2Dir + '_vol'
   l2volflow.connect([(l2volSource,onesamplettestdes,[('outfiles','in_files')]),
                      (onesamplettestdes,l2estimate,[('spm_mat_file','spm_mat_file')]),
                      (l2estimate,l2conestimate,[('spm_mat_file','spm_mat_file'),
                                                 ('beta_images','beta_images'),
                                                 ('residual_image','residual_image')
                                                 ]),
                      (l2conestimate, l2volflowthresh,[('spm_mat_file','spm_mat_file'),
                                                       ('spmT_images','stat_image'),
                                                       ]),
                      ])

   
Analysis on the Surface
=======================

An important difference between the format of the volume and the surface data is, that the surface data are img-files and are seperated for both hemispheres. In contrast the volume data is in nifti-files which contain both hemispheres. This separation means that we have to iterate over the left ('lh') and the right ('rh') hemisphere.

Grab the data
~~~~~~~~~~~~~

As mentioned above, our **second level surface pipeline** does have to iterate over the different contrasts **and** the left and right hemisphere. This can be done with the usual individually defined ``IdentityInterface`` node.

.. code-block:: py

   #Node: IdentityInterface - to iterate over contrasts and hemispheres
   l2surfinputnode = pe.Node(interface=util.IdentityInterface(fields=['contrasts','hemi']),
                             name='l2surfinputnode')
   l2surfinputnode.iterables = [('contrasts', contrast_ids),
                                ('hemi', ['lh','rh'])]


Again we have to be aware about the structure of our data folder. We know from the **first level analaysis pipeline** that our estimated surface contrasts are stored at: '~SOMEPATH/experiment/result/level1_output/'. This will be defined as ``base_directory`` of the datagrabber node.

.. code-block:: py

   #Node: DataGrabber - to collect contrast images and registration files
   l2surfSource = pe.Node(interface=nio.DataGrabber(infields=['con_id'],
                                                    outfields=['con','reg']),
                          name='l2surfSource')
   l2surfSource.inputs.base_directory = experiment_dir + '/level1_output/'
   l2surfSource.inputs.template = '*'
   l2surfSource.inputs.field_template = dict(con='surf_contrasts/_subject_id_*/con_%04d.img',
                                             reg='bbregister/_subject_id_*/*.dat')
   l2surfSource.inputs.template_args = dict(con=[['con_id']],reg=[[]])


Define nodes
~~~~~~~~~~~~

Now that we have defined where our data comes frome, we can start with implementing the nodes.

.. code-block:: py

   #Node: Merge - to merge contrast images and registration files
   merge = pe.Node(interface=util.Merge(2, axis='hstack'),name='merge')

   #function to create a list of all subjects and the location of their specific files
   def ordersubjects(files, subj_list):
       outlist = []
       for subject in subj_list:
           for subj_file in files:
               if '/_subject_id_%s/'%subject in subj_file:
                   outlist.append(subj_file)
                   continue
   return outlist

   #Node: MRISPreproc - to concatenate contrast images projected to fsaverage
   concat = pe.Node(interface=fs.MRISPreproc(), name='concat')
   concat.inputs.target = 'fsaverage'
   concat.inputs.fwhm = 5  #the smoothing of the surface data happens here

   #function that transformes a given list into tuples
   def list2tuple(listoflist):
       return [tuple(x) for x in listoflist]

   ###   #Node: OneSampleTTest - to perform a one sample t-test
   ###   oneSampleTTestDes = pe.Node(interface=fs.OneSampleTTest(), name='oneSampleTTestDes')
   

**!!!!!!!!!!!!gaht das Ã¼berhaupt?!!!!!!!!!!!!!!**

.. note::

   As you can see the oneSampleTTestDes in this surface pipeline is actually the same as the one from the volume pipeline. Because we are not integrating those two pipeline in a common parent workflow we won't have any issue with duplication and connection errors because the surface and the volume pipeline will always we executed independent of each other.


Establish a second level surface pipeline
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: py

   #Create 2-level surf pipeline and connect up all components
   l2surfflow = pe.Workflow(name='l2surfflow')
   l2surfflow.base_dir = experiment_dir + level2Dir + '_surf'
   l2surfflow.connect([(l2surfinputnode,l2surfSource,[('contrasts','con_id')]),
                       (l2surfinputnode,concat,[('hemi','hemi')]),
                       (l2surfSource,merge,[(('con', ordersubjects, subjects),'in1'),
	                                    (('reg', ordersubjects, subjects),'in2')]),
                       (merge,concat,[(('out', list2tuple),'vol_measure_file')]),
                       (concat,oneSampleTTestDes,[('out_file','in_file')]),
	                    ])


Datasink (optional)
===================

If you want to store the data from the second level volume and surface pipeline at a common location you should use a ``datasink`` node. As with the ``oneSampleTTestDes`` node before you can use the same ``datasink`` node for both pipelines because you aren't running both pipelines in the same run.

.. code-block:: py

   #Node: Datasink - Create a datasink node to store important outputs
   l2datasink = pe.Node(interface=nio.DataSink(), name="l2datasink")
   l2datasink.inputs.base_directory = experiment_dir
   l2datasink.inputs.container = level2Dir + '_datasink'

   #integration of the datasink into the volume analysis pipeline
   ###   l2volflow.connect([(l2conestimate,l2datasink,[('inputbla','outputbla')]),
   ###                      (l2volflowthresh,l2datasink,[('inputbla','outputbla')]),
   ###                      ])

   #integration of the datasink into the surface analysis pipeline
   l2surfflow.connect([(oneSampleTTestDes,l2datasink,[('sig_file','sig_file')])])


Run pipeline
============

Now that we have set up both pipelines we are able to run them. Note that those lines of codes mean that the **second level surface pipeline** won't be started before the **second level volume pipeline** has terminated.

.. code-block:: py

   l2volflow.write_graph(graph2use='flat')
   l2volflow.run(plugin='MultiProc', plugin_args={'n_procs' : 2})

   l2surfflow.write_graph(graph2use='flat')
   l2surfflow.run(plugin='MultiProc', plugin_args={'n_procs' : 2})


.. hint::

   This code for the second level pipeline on the volume and on the surface can be found here: `secondlevelpipeline.py <http://github.com/miykael/nipype-beginner-s-guide/blob/master/secondlevelpipeline.py>`_


Visualization
=============

Second Level Volume Pipeline
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. image:: l2vol.jpg
   :width: 200 px


Second Level Surface Pipeline
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. image:: l2surf.jpg
   :width: 200 px
